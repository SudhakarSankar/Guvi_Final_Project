{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Processing using the punch of text using the streamlit application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import stanza\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import ne_chunk\n",
    "from rake_nltk import Rake\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download necessary resources for NLTK\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Initialize Stanza pipeline for POS tagging\n",
    "# # stanza.download('en')\n",
    "# nlp_stanza = stanza.Pipeline(lang='en', processors='tokenize,pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text (First 500 characters):\n",
      " Scarface, a legendary alpha lion of the Maasai Mara National Reserve in Kenya, was known for his resilience, dominance, and survival skills, earning him fame among tourists and wildlife enthusiasts. He died of natural causes on June 11, 2021, at the age of 14, after a life marked by territorial battles and encounters with other predators. \n",
      "Key aspects of Scarface's story:\n",
      "Dominance and Resilience:\n",
      "Scarface was a dominant male lion, known for his ability to survive and thrive despite facing numer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Read the text file\n",
    "file_path = \"C:/Sudhakar/Projects/Guvi Final Project/NLP/Dataset and Document/Scar lion king.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(\"Original Text (First 500 characters):\\n\", text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization Output: ['Scarface', ',', 'a', 'legendary', 'alpha', 'lion', 'of', 'the', 'Maasai', 'Mara']\n",
      "\n",
      "Lowercased Tokens: ['scarface', ',', 'a', 'legendary', 'alpha', 'lion', 'of', 'the', 'maasai', 'mara']\n",
      "\n",
      "Stopword Removal Output: ['scarface', 'legendary', 'alpha', 'lion', 'maasai', 'mara', 'national', 'reserve', 'kenya', 'known']\n",
      "\n",
      "Stemming Output: ['scarfac', 'legendari', 'alpha', 'lion', 'maasai', 'mara', 'nation', 'reserv', 'kenya', 'known']\n",
      "\n",
      "Lemmatization Output: ['scarface', 'legendary', 'alpha', 'lion', 'maasai', 'mara', 'national', 'reserve', 'kenya', 'known']\n",
      "\n",
      "POS Tagging Output: [('scarface', 'NN'), ('legendary', 'JJ'), ('alpha', 'NN'), ('lion', 'NN'), ('maasai', 'NN'), ('mara', 'NNP'), ('national', 'JJ'), ('reserve', 'NN'), ('kenya', 'NNP'), ('known', 'VBN'), ('resilience', 'NN'), ('dominance', 'NN'), ('survival', 'NN'), ('skills', 'NNS'), ('earning', 'VBG'), ('fame', 'NN'), ('among', 'IN'), ('tourists', 'NNS'), ('wildlife', 'NN'), ('enthusiasts', 'NNS')]\n",
      "\n",
      "Extracted Keywords: ['thrive despite facing numerous challenges', 'maasai mara national reserve', 'maasai mara national reserve', 'captivating wildlife enthusiasts worldwide', 'fame among tourists', 'successful hunting skills', 'protective behavior towards', 'legendary alpha lion', 'dominant male lion', 'wildlife enthusiasts', 'wild lion', 'survival skills', 'protective nature', 'popular lion', 'vital role', 'territorial battles', 'territorial battles', 'territorial battle', 'still live', 'natural causes']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: NLP Preprocessing\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"\\nTokenization Output:\", tokens[:10])\n",
    "\n",
    "# Lowercasing\n",
    "tokens_lower = [word.lower() for word in tokens]\n",
    "print(\"\\nLowercased Tokens:\", tokens_lower[:10])\n",
    "\n",
    "# Stopword Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens_no_stopwords = [word for word in tokens_lower if word.isalpha() and word not in stop_words]\n",
    "print(\"\\nStopword Removal Output:\", tokens_no_stopwords[:10])\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in tokens_no_stopwords]\n",
    "print(\"\\nStemming Output:\", stemmed_tokens[:10])\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens_no_stopwords]\n",
    "print(\"\\nLemmatization Output:\", lemmatized_tokens[:10])\n",
    "\n",
    "# Part-of-Speech (POS) Tagging using Stanza\n",
    "doc = nlp_stanza(\" \".join(tokens_no_stopwords))\n",
    "pos_tags = [(word.text, word.xpos) for sent in doc.sentences for word in sent.words]\n",
    "print(\"\\nPOS Tagging Output:\", pos_tags[:20])\n",
    "\n",
    "rake = Rake()\n",
    "rake.extract_keywords_from_text(text)\n",
    "keywords = rake.get_ranked_phrases()[:20]  # Get top 20 keywords\n",
    "print(\"\\nExtracted Keywords:\", keywords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_data = {\n",
    "    \"tokens\": tokens,\n",
    "    \"tokens_lower\": tokens_lower,\n",
    "    \"tokens_no_stopwords\": tokens_no_stopwords,\n",
    "    \"stemmed_tokens\": stemmed_tokens,\n",
    "    \"lemmatized_tokens\": lemmatized_tokens,\n",
    "    \"pos_tags\": pos_tags,\n",
    "    \"keywords\": keywords\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\vsudh\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK resource for sentiment analysis\n",
    "nltk.download('vader_lexicon')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# # Input text (replace with your actual text variable)\n",
    "# file_path = \"C:/Sudhakar/Projects/Guvi Final Project/NLP/Dataset and Document/Scar lion king.txt\"\n",
    "\n",
    "# with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# Perform sentiment analysis\n",
    "sentiment_scores = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Determine overall sentiment label\n",
    "if sentiment_scores[\"compound\"] >= 0.05:\n",
    "    sentiment_label = \"Positive 😀\"\n",
    "elif sentiment_scores[\"compound\"] <= -0.05:\n",
    "    sentiment_label = \"Negative 😠\"\n",
    "else:\n",
    "    sentiment_label = \"Neutral 😐\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Analysis Scores: {'neg': 0.091, 'neu': 0.743, 'pos': 0.167, 'compound': 0.9322}\n",
      "Overall Sentiment: Positive 😀\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"\\nSentiment Analysis Scores:\", sentiment_scores)\n",
    "print(\"Overall Sentiment:\", sentiment_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
